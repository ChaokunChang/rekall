{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rekall Tutorial: Cyclist Detection\n",
    "\n",
    "In this tutorial, you'll learn how to use Rekall to detect a new class of objects (cyslists) from existing person and bicycle detections from Mask R-CNN.\n",
    "\n",
    "Let's first import Rekall and a few of its important classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from rekall import Interval, IntervalSet, IntervalSetMapping, Bounds3D\n",
    "from rekall.predicates import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tutorial, we'll provide some helpers to handle data loading videos and pre-computed object detections from our servers. Run this cell to load in those helpers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cyclist_tutorial_helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's load up the pre-computed bounding box detections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes = get_maskrcnn_bboxes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bboxes.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `visualize_helper` function to visualize these bounding boxes. Click on the video to expand it, and play the video by hovering over it and using `;`. You can navigate through the video by clicking through the timeline, and using the `+` and `-` buttons to zoom in or out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Interval t1:1.0 t2:1.1 x1:0.9520519213591989 x2:0.9992879231770834 y1:0.18309134928385418 y2:0.38728181966145836 payload:{'class': 'elephant', 'score': 0.7092806100845337, 'spatial_type': <vgrid.spatial_type.SpatialType_Bbox object at 0x0000022D215CFD00>}>,\n",
       " <Interval t1:2.5 t2:2.6 x1:0.8846395249911937 x2:0.9052875905797102 y1:0.6124517822265625 y2:0.7083091634114583 payload:{'class': 'frisbee', 'score': 0.7335711717605591, 'spatial_type': <vgrid.spatial_type.SpatialType_Bbox object at 0x0000022D215CFE20>}>,\n",
       " <Interval t1:2.5 t2:2.6 x1:0.9103485942846719 x2:0.9439891870471014 y1:0.5886897786458334 y2:0.881246826171875 payload:{'class': 'person', 'score': 0.7251530885696411, 'spatial_type': <vgrid.spatial_type.SpatialType_Bbox object at 0x0000022D215CFF40>}>,\n",
       " <Interval t1:11.5 t2:11.6 x1:0.05118782547169069 x2:0.09615725825950143 y1:0.32522682698567706 y2:0.37818359375 payload:{'class': 'car', 'score': 0.9560763239860535, 'spatial_type': <vgrid.spatial_type.SpatialType_Bbox object at 0x0000022D215D20A0>}>,\n",
       " <Interval t1:11.6 t2:11.7 x1:0.03141938852995106 x2:0.08704269335465731 y1:0.35526713053385417 y2:0.4093762613932292 payload:{'class': 'car', 'score': 0.9739233255386353, 'spatial_type': <vgrid.spatial_type.SpatialType_Bbox object at 0x0000022D215D21C0>}>,\n",
       " <Interval t1:11.7 t2:11.8 x1:0.026540618011916893 x2:0.07768337968466939 y1:0.3876166178385417 y2:0.44635127766927085 payload:{'class': 'car', 'score': 0.9890377521514893, 'spatial_type': <vgrid.spatial_type.SpatialType_Bbox object at 0x0000022D215D22E0>}>,\n",
       " <Interval t1:11.8 t2:11.9 x1:0.010046697853076093 x2:0.06794009001358696 y1:0.39467936197916664 y2:0.4562623291015625 payload:{'class': 'car', 'score': 0.952527642250061, 'spatial_type': <vgrid.spatial_type.SpatialType_Bbox object at 0x0000022D215D2400>}>,\n",
       " <Interval t1:11.9 t2:12.0 x1:0.0044180129845169235 x2:0.05949124813847688 y1:0.38066426595052083 y2:0.43832914225260416 payload:{'class': 'car', 'score': 0.9784989356994629, 'spatial_type': <vgrid.spatial_type.SpatialType_Bbox object at 0x0000022D215D2520>}>,\n",
       " <Interval t1:12.0 t2:12.1 x1:0.0 x2:0.046210643749882055 y1:0.37511690266927084 y2:0.43822749837239583 payload:{'class': 'car', 'score': 0.992733359336853, 'spatial_type': <vgrid.spatial_type.SpatialType_Bbox object at 0x0000022D215D2640>}>,\n",
       " <Interval t1:12.1 t2:12.2 x1:0.0007970946422521619 x2:0.036740172504418904 y1:0.39539005533854166 y2:0.4586077473958333 payload:{'class': 'car', 'score': 0.972437858581543, 'spatial_type': <vgrid.spatial_type.SpatialType_Bbox object at 0x0000022D215D2760>}>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bboxes[3].get_intervals()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f930d2e3e36447fa8cc684e127b414a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VGridWidget(vgrid_spec={'compressed': True, 'data': b'x\\x9c\\xcc\\xbd\\xdb\\xae&K\\x92\\x9c\\xf7*D_\\x0bB\\x9c\\x0f\\xba\\…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_helper([bboxes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering on Payload\n",
    "Let's give a preview of some of the things you'll be able to do with Rekall. In the above two cells we've loaded up bounding box detections over two videos, and visualized them for you.\n",
    "\n",
    "Let's start by filtering the bounding box detections by class to look at bicycle and person detections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes = bboxes.filter(lambda interval: interval['payload']['class'] == 'bicycle')\n",
    "person = bboxes.filter(lambda interval: interval['payload']['class'] == 'person')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's visualize them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e57c6ef383844f288dc9c0dd5d6c7780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VGridWidget(vgrid_spec={'compressed': True, 'data': b'x\\x9c\\xd4\\x9d\\xcb\\xae,Ir]\\x7f\\x85\\xa81\\xd1\\xf0\\xf7CC\\xfd…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_helper([bikes, person])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3927, 1625\n",
      "369, 50\n",
      "Time cost:  0.24300336837768555\n",
      "635, 97\n",
      "142, 14\n"
     ]
    }
   ],
   "source": [
    "# Try some payload filtering functions yourself here!\n",
    "print(f'{len(person[0])}, {len(bikes[0])}')\n",
    "print(f'{len(person[3])}, {len(bikes[3])}')\n",
    "\n",
    "import time\n",
    "t = time.time()\n",
    "bikes = bikes.coalesce(\n",
    "    ('t1', 't2'),\n",
    "    bounds_merge_op=Bounds3D.span,\n",
    "    payload_merge_op=lambda payload1, payload2: {\"score\": max(payload1['score'], payload2['score']), \"class\":payload1['class']},\n",
    "    predicate=and_pred(\n",
    "        lambda intrvl1, intrvl2: intrvl1['payload']['class'] == intrvl2['payload']['class'],\n",
    "        Bounds3D.X(overlaps()),\n",
    "        Bounds3D.Y(overlaps())\n",
    "    ),\n",
    "    epsilon=0\n",
    ")\n",
    "person = person.coalesce(\n",
    "    ('t1', 't2'),\n",
    "    bounds_merge_op=Bounds3D.span,\n",
    "    payload_merge_op=lambda payload1, payload2: {\"score\": max(payload1['score'], payload2['score']), \"class\":payload1['class']},\n",
    "    predicate=and_pred(\n",
    "        lambda intrvl1, intrvl2: intrvl1['payload']['class'] == intrvl2['payload']['class'],\n",
    "        and_pred(\n",
    "        Bounds3D.X(overlaps()),\n",
    "        Bounds3D.Y(overlaps()))\n",
    "    ) ,\n",
    "    epsilon=0\n",
    ")\n",
    "t = time.time() - t\n",
    "print(\"Time cost: \", t)\n",
    "\n",
    "print(f'{len(person[0])}, {len(bikes[0])}')\n",
    "print(f'{len(person[3])}, {len(bikes[3])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1.0000000000000009,\n",
       " 0.9999999999999964,\n",
       " 0.9999999999999787,\n",
       " 0.9999999999999787,\n",
       " 1.0000000000000142,\n",
       " 1.0000000000000142,\n",
       " 4.000000000000057,\n",
       " 27.00000000000003,\n",
       " 1.0000000000000853,\n",
       " 1.0000000000000853,\n",
       " 1.0000000000000853,\n",
       " 0.9999999999999432,\n",
       " 2.0000000000000284,\n",
       " 1.0000000000000853,\n",
       " 0.9999999999999432,\n",
       " 0.9999999999999432,\n",
       " 2.0000000000000284,\n",
       " 0.9999999999999432,\n",
       " 1.9999999999998863,\n",
       " 0.9999999999999432,\n",
       " 0.9999999999999432,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 0.9999999999996589,\n",
       " 0.9999999999996589,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 0.9999999999996589,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 0.9999999999996589,\n",
       " 1.0000000000002274,\n",
       " 0.9999999999996589,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 0.9999999999996589,\n",
       " 2.0000000000004547,\n",
       " 86.00000000000023,\n",
       " 0.9999999999996589,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 1.9999999999998863,\n",
       " 1.0000000000002274,\n",
       " 0.9999999999996589,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 0.9999999999990905,\n",
       " 0.9999999999990905,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 0.9999999999990905,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 1.9999999999993179,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 0.9999999999990905,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 0.9999999999990905,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 3.9999999999997726,\n",
       " 0.9999999999990905,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 0.9999999999990905,\n",
       " 1.0000000000002274,\n",
       " 5.9999999999990905,\n",
       " 2.0000000000004547,\n",
       " 11.000000000000227,\n",
       " 8.999999999999773,\n",
       " 2.0000000000004547,\n",
       " 2.0000000000004547,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 1.9999999999993179,\n",
       " 2.9999999999995453,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 2.0000000000004547,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 0.9999999999990905,\n",
       " 1.0000000000002274,\n",
       " 0.9999999999990905,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 0.9999999999990905,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 0.9999999999990905,\n",
       " 1.0000000000002274,\n",
       " 0.9999999999990905,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 2.0000000000004547,\n",
       " 3.000000000000682,\n",
       " 3.9999999999997726,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 2.0000000000004547,\n",
       " 2.0000000000004547,\n",
       " 1.0000000000002274,\n",
       " 0.9999999999990905,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 1.0000000000002274,\n",
       " 16.999999999999318]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_len = [10*intrvl.size() for intrvl in person[3].get_intervals()]\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(person_len)\n",
    "plt.show()\n",
    "person_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAALQUlEQVR4nO3cXYgdhRnG8edpVvEbW3Iq1rhdpWIrgo0sVhuQNkqJjWgvWlBQrAh7Y20sgsTelN5FKKIXIgQ/QatIVCqmtYofiNCmzapt1SiVNNXU2KyI9eOiqfr04pyYTTxxRz2z85r9/2DZ8zGZ8zLZ889kzsw6iQAAdX2h6wEAAB+PUANAcYQaAIoj1ABQHKEGgOLG2ljp4sWLMzEx0caqAWCfND09/XqS3rDnWgn1xMSENm7c2MaqAWCfZPufe3uOQx8AUByhBoDiCDUAFEeoAaA4Qg0AxRFqACiuUahtH257ne0XbG+yfVrbgwEA+pqeR32dpAeT/ND2/pIOanEmAMAsc4ba9mGSTpf0Y0lKskPSjnbHAgDs1GSP+lhJM5JusX2SpGlJq5K8O3sh21OSpiRpfHz8Uw80sXr9p/6zn8WWNSs7eV0AmEuTY9Rjkk6WdEOSpZLelbR6z4WSrE0ymWSy1xt6uToA4FNoEuqtkrYm2TC4v079cAMA5sGcoU7ymqRXbB8/eOgMSc+3OhUA4ENNz/q4TNIdgzM+Nku6uL2RAACzNQp1kmckTbY7CgBgGK5MBIDiCDUAFEeoAaA4Qg0AxRFqACiOUANAcYQaAIoj1ABQHKEGgOIINQAUR6gBoDhCDQDFEWoAKI5QA0BxhBoAiiPUAFAcoQaA4gg1ABRHqAGgOEINAMURagAojlADQHGEGgCKI9QAUByhBoDixposZHuLpLclvS/pvSSTbQ4FANilUagHvpvk9dYmAQAMxaEPACiuaagj6SHb07anhi1ge8r2RtsbZ2ZmRjchACxwTUO9LMnJks6SdKnt0/dcIMnaJJNJJnu93kiHBICFrFGok7w6+L5d0n2STmlzKADALnOG2vbBtg/deVvS9yQ92/ZgAIC+Jmd9HCHpPts7l/91kgdbnQoA8KE5Q51ks6ST5mEWAMAQnJ4HAMURagAojlADQHGEGgCKI9QAUByhBoDiCDUAFEeoAaA4Qg0AxRFqACiOUANAcYQaAIoj1ABQHKEGgOIINQAUR6gBoDhCDQDFEWoAKI5QA0BxhBoAiiPUAFAcoQaA4gg1ABRHqAGgOEINAMURagAornGobS+y/bTtB9ocCACwu0+yR71K0qa2BgEADNco1LaXSFop6cZ2xwEA7KnpHvW1kq6U9MHeFrA9ZXuj7Y0zMzOjmA0AoAahtn22pO1Jpj9uuSRrk0wmmez1eiMbEAAWuiZ71MsknWN7i6S7JC23fXurUwEAPjRnqJNclWRJkglJ50l6NMkFrU8GAJDEedQAUN7YJ1k4yeOSHm9lEgDAUOxRA0BxhBoAiiPUAFAcoQaA4gg1ABRHqAGgOEINAMURagAojlADQHGEGgCKI9QAUByhBoDiCDUAFEeoAaA4Qg0AxRFqACiOUANAcYQaAIoj1ABQHKEGgOIINQAUR6gBoDhCDQDFEWoAKI5QA0Bxc4ba9gG2/2T7L7afs/3L+RgMANA31mCZ/0panuQd2/tJetL275L8seXZAABqEOokkfTO4O5+g6+0ORQAYJcme9SyvUjStKSvSbo+yYYhy0xJmpKk8fHxUc44LyZWr+/stbesWdnZawOor9GHiUneT/JNSUsknWL7xCHLrE0ymWSy1+uNeEwAWLg+0VkfSd6U9LikFW0MAwD4qCZnffRsHz64faCkMyW90PJcAICBJseoj5R02+A49Rck3Z3kgXbHAgDs1OSsj79KWjoPswAAhuDKRAAojlADQHGEGgCKI9QAUByhBoDiCDUAFEeoAaA4Qg0AxRFqACiOUANAcYQaAIoj1ABQHKEGgOIINQAUR6gBoDhCDQDFEWoAKI5QA0BxhBoAiiPUAFAcoQaA4gg1ABRHqAGgOEINAMURagAojlADQHFzhtr20bYfs73J9nO2V83HYACAvrEGy7wn6YokT9k+VNK07YeTPN/ybAAANdijTrItyVOD229L2iTpqLYHAwD0Ndmj/pDtCUlLJW0Y8tyUpClJGh8fH8VsAEZgYvX6Tl53y5qVnbzuvqjxh4m2D5F0j6TLk7y15/NJ1iaZTDLZ6/VGOSMALGiNQm17P/UjfUeSe9sdCQAwW5OzPizpJkmbklzT/kgAgNma7FEvk3ShpOW2nxl8fb/luQAAA3N+mJjkSUmeh1kAAENwZSIAFEeoAaA4Qg0AxRFqACiOUANAcYQaAIoj1ABQHKEGgOIINQAUR6gBoDhCDQDFEWoAKI5QA0BxhBoAiiPUAFAcoQaA4gg1ABRHqAGgOEINAMURagAojlADQHGEGgCKI9QAUByhBoDiCDUAFDdnqG3fbHu77WfnYyAAwO6a7FHfKmlFy3MAAPZizlAneULSG/MwCwBgiLFRrcj2lKQpSRofHx/VaheEidXrux5h3m1Zs7LrEbAP6+o91dbP9cg+TEyyNslkkslerzeq1QLAgsdZHwBQHKEGgOKanJ53p6Q/SDre9lbbl7Q/FgBgpzk/TExy/nwMAgAYjkMfAFAcoQaA4gg1ABRHqAGgOEINAMURagAojlADQHGEGgCKI9QAUByhBoDiCDUAFEeoAaA4Qg0AxRFqACiOUANAcYQaAIoj1ABQHKEGgOIINQAUR6gBoDhCDQDFEWoAKI5QA0BxhBoAiiPUAFAcoQaA4hqF2vYK2y/afsn26raHAgDsMmeobS+SdL2ksySdIOl82ye0PRgAoK/JHvUpkl5KsjnJDkl3STq33bEAADuNNVjmKEmvzLq/VdK39lzI9pSkqcHdd2y/+NnH69RiSa93PUQRI98WvnqUa5t3/Gzsbuj2+Jz/HX8qvvoz/Wx8dW9PNAm1hzyWjzyQrJW09hMMVZrtjUkmu56jArbF7tgeu2N77NLWtmhy6GOrpKNn3V8i6dVRDwIAGK5JqP8s6Tjbx9jeX9J5ku5vdywAwE5zHvpI8p7tn0j6vaRFkm5O8lzrk3VvnzmMMwJsi92xPXbH9tillW3h5COHmwEAhXBlIgAUR6gBoDhCPYvto20/ZnuT7edsr+p6pq7ZXmT7adsPdD1L12wfbnud7RcGPyOndT1Tl2z/bPA+edb2nbYP6Hqm+WT7ZtvbbT8767Ev2X7Y9t8H3784itci1Lt7T9IVSb4h6VRJl3K5vFZJ2tT1EEVcJ+nBJF+XdJIW8HaxfZSkn0qaTHKi+icanNftVPPuVkkr9nhstaRHkhwn6ZHB/c+MUM+SZFuSpwa331b/jXhUt1N1x/YSSSsl3dj1LF2zfZik0yXdJElJdiR5s9Ohujcm6UDbY5IO0gK7viLJE5Le2OPhcyXdNrh9m6QfjOK1CPVe2J6QtFTSho5H6dK1kq6U9EHHc1RwrKQZSbcMDgXdaPvgrofqSpJ/SfqVpJclbZP0nyQPdTtVCUck2Sb1d/wkfXkUKyXUQ9g+RNI9ki5P8lbX83TB9tmStieZ7nqWIsYknSzphiRLJb2rEf239vNocOz1XEnHSPqKpINtX9DtVPsuQr0H2/upH+k7ktzb9TwdWibpHNtb1P+Nictt397tSJ3aKmlrkp3/w1qnfrgXqjMl/SPJTJL/SbpX0rc7nqmCf9s+UpIG37ePYqWEehbbVv8Y5KYk13Q9T5eSXJVkSZIJ9T8kejTJgt1jSvKapFdsHz946AxJz3c4UtdelnSq7YMG75sztIA/XJ3lfkkXDW5fJOk3o1hpk9+et5Ask3ShpL/Zfmbw2M+T/La7kVDIZZLuGPzOm82SLu54ns4k2WB7naSn1D9b6mktsEvJbd8p6TuSFtveKukXktZIutv2Jer/Y/ajkbwWl5ADQG0c+gCA4gg1ABRHqAGgOEINAMURagAojlADQHGEGgCK+z/o8VFLlErMPgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[2.0000000000000284,\n",
       " 7.999999999999972,\n",
       " 0.9999999999999432,\n",
       " 1.0000000000000853,\n",
       " 0.9999999999999432,\n",
       " 1.0000000000002274,\n",
       " 0.9999999999996589,\n",
       " 1.0000000000002274,\n",
       " 2.9999999999995453,\n",
       " 7.999999999999545,\n",
       " 3.9999999999997726,\n",
       " 1.9999999999998863,\n",
       " 10.0,\n",
       " 1.9999999999998863]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes_len = [10*intrvl.size() for intrvl in bikes[3].get_intervals()]\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(bikes_len)\n",
    "plt.show()\n",
    "bikes_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deded7f5d22f4965bdb85c93a2969b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VGridWidget(vgrid_spec={'compressed': True, 'data': b'x\\x9c\\xcd\\x9dK\\x8f]\\xd7\\x91\\xa5\\xffJC=m\\xc8\\xfb\\xfd\\xa8A…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_helper([\n",
    "    bikes.filter(lambda interval: interval['t1'] < 300),\n",
    "    person.filter(lambda interval: interval['t1'] < 300)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try some bounds filtering functions yourself here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rekall's Data Model\n",
    "\n",
    "Now that we have a flavor of what we can do with Rekall, let's build our understanding of the data representation from the ground up. Let's first understand what `Interval`s are - these are the fundamental data structure that we use to represent any annotations in videos.\n",
    "\n",
    "Here's a figure demonstrating what these Intervals can look like:\n",
    "\n",
    "![video_volume_v2.png](https://storage.googleapis.com/esper/dan_olimar/rekall_tutorials/videovolume_v2.png)\n",
    "\n",
    "Intervals are parameterized by a Bounds object (`Bounds3D` in all the intervals above), and an optional payload (face identities, word in the caption, or nested Intervals in the figure above):\n",
    "\n",
    "```Python\n",
    "# This interval has time bounds from 0 to 10 seconds, X bounds from 0.5 to 0.7 (frame-relative),\n",
    "# and Y bounds from 0.6 to 0.9 (frame-relative)\n",
    "new_interval = Interval(Bounds3D(\n",
    "    t1 = 0,\n",
    "    t2 = 10,\n",
    "    x1 = 0.5,\n",
    "    x2 = 0.7,\n",
    "    y1 = 0.6,\n",
    "    y2 = 0.9\n",
    "))\n",
    "\n",
    "# This interval has time bounds from 5 to 15 seconds, and default X and Y bounds of the whole\n",
    "# frame (0 to 1 for both X and Y)\n",
    "new_interval2 = Interval(Bounds3D(5, 15))\n",
    "\n",
    "# This interval has a payload. The payload can be an arbitrary object.\n",
    "new_interval3 = Interval(Bounds3D(0, 1), payload={ 'class': 'my first payload' })\n",
    "                         \n",
    "# We can access the co-ordinates of payload and an Interval directly\n",
    "print(new_interval['t1'], new_interval['t2'], new_interval['x1'])\n",
    "print(new_interval2['t1'], new_interval2['x1'])\n",
    "print(new_interval3['payload'])\n",
    "print(new_interval3['payload']['class'])\n",
    "```\n",
    "\n",
    "Try it yourself below!\n",
    "\n",
    "**NB: If you're coming from the paper/tech report, the words \"Label\" are \"Interval\" are interchangeable in the code.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10 0.5\n",
      "5 0.0\n",
      "{'class': 'my first payload'}\n",
      "my first payload\n"
     ]
    }
   ],
   "source": [
    "# This interval has time bounds from 0 to 10 seconds, X bounds from 0.5 to 0.7 (frame-relative),\n",
    "# and Y bounds from 0.6 to 0.9 (frame-relative)\n",
    "new_interval = Interval(Bounds3D(\n",
    "    t1 = 0,\n",
    "    t2 = 10,\n",
    "    x1 = 0.5,\n",
    "    x2 = 0.7,\n",
    "    y1 = 0.6,\n",
    "    y2 = 0.9\n",
    "))\n",
    "\n",
    "# This interval has time bounds from 5 to 15 seconds, and default X and Y bounds of the whole\n",
    "# frame (0 to 1 for both X and Y)\n",
    "new_interval2 = Interval(Bounds3D(5, 15))\n",
    "\n",
    "# This interval has a payload. The payload can be an arbitrary object.\n",
    "new_interval3 = Interval(Bounds3D(0, 1), payload={ 'class': 'my first payload' })\n",
    "\n",
    "# We can access the co-ordinates of payload and an Interval directly\n",
    "print(new_interval['t1'], new_interval['t2'], new_interval['x1'])\n",
    "print(new_interval2['t1'], new_interval2['x1'])\n",
    "print(new_interval3['payload'])\n",
    "print(new_interval3['payload']['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some Intervals yourself here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Associating Intervals with Events\n",
    "In Rekall, we use *sets* of Intervals to represent events in videos. A single `IntervalSet` contains all occurrences of an event in a single video (all the bounding box detections, all the cyclist annotations, etc).\n",
    "\n",
    "We can create an `IntervalSet` by passing in a list of `Interval`s:\n",
    "\n",
    "```Python\n",
    "# This IntervalSet represents all occurrences of a \"made up\" event in a video\n",
    "my_first_intervalset = IntervalSet([\n",
    "    Interval(Bounds3D(0, 10), payload = { 'class': 'made up'} ),\n",
    "    Interval(Bounds3D(20, 30), payload = { 'class': 'made up'} ),\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_first_intervalset = IntervalSet([\n",
    "    Interval(Bounds3D(0, 10), payload = { 'class': 'made up'} ),\n",
    "    Interval(Bounds3D(20, 30), payload = { 'class': 'made up'} ),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last thing - we want to associate each `IntervalSet` with the right video. We might have detected bikes in one video, but not the other!\n",
    "\n",
    "We use `IntervalSetMapping` to associate `IntervalSet`s with different videos by keys. We create an `IntervalSetMapping` by passing in a `dict` from \n",
    "\n",
    "```Python\n",
    "my_first_ism = IntervalSetMapping({\n",
    "    0: IntervalSet(...), # the IntervalSet for video 0\n",
    "    2: IntervalSet(...) # the IntervalSet for video 2\n",
    "})\n",
    "```\n",
    "\n",
    "`bboxes` is an `IntervalSetMapping` object that we pre-loaded with `Interval`s containing object detections from Mask-RCNN.\n",
    "\n",
    "Similarly, `bikes` and `person` are `IntervalSetMapping` objects representing the event that a bicycle object or a person object was detected in the video.\n",
    "\n",
    "We can look at the keys of one of the `IntervalSetMapping` objects to see what the keys in our videos are!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bboxes.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The videos that we were looking at before have keys 0 and 3. The visualization shows the videos in sorted order, so we know that the first video is video 0, and the second video is video 3.\n",
    "\n",
    "Now we can create a simple `IntervalSetMapping` and visualize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_first_ism = IntervalSetMapping({\n",
    "    0: my_first_intervalset,\n",
    "    3: IntervalSet([Interval(Bounds3D(50, 60, 0.5, 0.8, 0.1, 0.3)), Interval(Bounds3D(100,200))])\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9921af3322e648c7baf525d0545daab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VGridWidget(vgrid_spec={'compressed': True, 'data': b'x\\x9c\\xcdTM\\x8f\\x9b0\\x10\\xfd++z\\xad\\xc0\\xe4k\\xb79\\xec\\xa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_helper([my_first_ism])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try it yourself below! Create some new `IntervalSetMapping` objects and visualize them on our videos.\n",
    "\n",
    "**NB: if you try to visualize an `IntervalSet` with only a single Interval in it, the timeline may not appear until you click on the video.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it yourself!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint: check on your understanding\n",
    "\n",
    "At this point, you should be familiar with a few concepts:\n",
    "* We represent events in videos as *sets* of intervals - objects that are defined by a Bounds object and an optional payload\n",
    "* An `IntervalSet` represents all the occurrences of a particular event in a single video\n",
    "* An `IntervalSetMapping` organizes multiple `IntervalSet`s and associates each one with a different video\n",
    "\n",
    "Since we told you that `bboxes_cydet` and `cyclist_gt` are `IntervalSetMapping` objects, you may have also surmised that we have some functions for manipulating these sets of intervals - we've already looked at a few examples of the `filter` function. But now that we know more about the underlying data representation, we can take a closer look at `filter`.\n",
    "\n",
    "From the [documentation](https://rekallpy.readthedocs.io/en/latest/index.html#rekall.IntervalSet.filter):\n",
    "\n",
    "```Python\n",
    "def filter(self, predicate):\n",
    "    \"\"\"\n",
    "    Filter the set and keep intervals that pass the predicate.\n",
    "    \n",
    "    Args:\n",
    "        predicate: A function that takes an Interval and returns a bool.\n",
    "        \n",
    "    Returns:\n",
    "        A new IntervalSet which is the filtered set.\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "So `filter` expects a function that will take an `Interval` and return `True` or `False`. It runs the predicate function on every interval, and only keeps the ones where the predicate returns `True`.\n",
    "\n",
    "Notice that the documentation says that `filter` returns a new `IntervalSet` - that's because it's actually a function on `IntervalSet`! `IntervalSetMapping` simply reflects all the functions in `IntervalSet` and applies the functions to every `IntervalSet`. So even though we wrote the function over `IntervalSet`s, we can run them on `IntervalSetMapping` objects like `bboxes_cydet` and `cyclist_gt`.\n",
    "\n",
    "## Checkpoint exercise: duplicate certain labels across the entirety of a video\n",
    "Let's go through a simple exercise to check your understanding of these concepts.\n",
    "\n",
    "We'll define a simple `IntervalSetMapping` with a few objects. We'll want you to duplicate the Intervals at time 0 of video 0 throughout videos 0 and 3, but only if the class in their payload is `car`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_to_duplicate = IntervalSetMapping({\n",
    "    0: IntervalSet([\n",
    "        Interval(Bounds3D(0, 10, 0.1, 0.3, 0.1, 0.9), payload={ 'class': 'car' }),\n",
    "        Interval(Bounds3D(0, 10, 0.4, 0.6, 0.1, 0.9), payload={ 'class': 'car' }),\n",
    "        Interval(Bounds3D(0, 10, 0.7, 0.9, 0.1, 0.9), payload={ 'class': 'godzilla' }),\n",
    "        Interval(Bounds3D(10, 20, 0.1, 0.3, 0.1, 0.9), payload={ 'class': 'car' }),\n",
    "        Interval(Bounds3D(10, 20, 0.4, 0.6, 0.1, 0.9), payload={ 'class': 'car' }),\n",
    "        Interval(Bounds3D(10, 20, 0.7, 0.9, 0.1, 0.9), payload={ 'class': 'godzilla' })\n",
    "    ]),\n",
    "    3: IntervalSet([\n",
    "        Interval(Bounds3D(0, 10, 0.2, 0.4, 0.1, 0.9), payload={ 'class': 'car' }),\n",
    "        Interval(Bounds3D(0, 10, 0.5, 0.7, 0.1, 0.9), payload={ 'class': 'car' }),\n",
    "        Interval(Bounds3D(0, 10, 0.75, 0.95, 0.1, 0.9), payload={ 'class': 'godzilla' }),\n",
    "        Interval(Bounds3D(10, 20, 0.2, 0.4, 0.1, 0.9), payload={ 'class': 'car' }),\n",
    "        Interval(Bounds3D(10, 20, 0.5, 0.7, 0.1, 0.9), payload={ 'class': 'car' }),\n",
    "        Interval(Bounds3D(10, 20, 0.75, 0.95, 0.1, 0.9), payload={ 'class': 'godzilla' })\n",
    "    ])\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particular, we'll want the resulting Intervals to have the following properties:\n",
    "* You should have Intervals with time extents of (0, 10), (10, 20), (20, 30), etc.\n",
    "* The Intervals should have the same X/Y extent and payload as the Intervals at *time 0* of video 0 that have payload 'car'.\n",
    "* The Intervals should cover the entire video.\n",
    "\n",
    "A few hints to get you started:\n",
    "* You can access `IntervalSet 0` of `objects_to_duplicate` like this: `objects_to_duplicate[0]`.\n",
    "* You can loop through all the video keys of `objects_to_duplicate` using an iterator: `[k for k in objects_to_duplicate]`.\n",
    "* You can filter down to Intervals that start at time 0 like this: `objects_to_duplicate.filter(lambda interval: interval['t0'] == 0)`\n",
    "* You can access all the Intervals in an `IntervalSet` like this: `objects_to_duplicate[0].get_intervals()`. This will return a list of Intervals sorted by time.\n",
    "* For example, to get the t2 value of the last interval in `bboxes_cydet`: `bboxes_cydet[0].get_intervals()[-1]['t2']`\n",
    "* You can access the bounds of an interval like so: `interval['bounds']`\n",
    "* You can copy a bounds like so: `interval['bounds'].copy()`\n",
    "* Remember you can use Python ranges to get a value every ten seconds: `range(0, end, 10)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct an IntervalSetMapping with the answer here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise solution:\n",
    "\n",
    "Example solution to this exercise - don't look if you haven't tried it!\n",
    "\n",
    "```Python\n",
    "objects_at_start = objects_to_duplicate[0].filter(\n",
    "    lambda interval: interval['t1'] == 0 and interval['payload']['class'] == 'car'\n",
    ").get_intervals()\n",
    "\n",
    "video_lengths = {\n",
    "    key: bboxes_cydet[key].get_intervals()[-1]['t2']\n",
    "    for key in bboxes_cydet\n",
    "}\n",
    "\n",
    "objects_duplicated = IntervalSetMapping({\n",
    "    key: IntervalSet([\n",
    "        Interval(Bounds3D(\n",
    "            t1 = t,\n",
    "            t2 = t + 10,\n",
    "            x1 = interval['x1'],\n",
    "            x2 = interval['x2'],\n",
    "            y1 = interval['y1'],\n",
    "            y2 = interval['y2']\n",
    "        ))\n",
    "        for t in range(0, int(video_lengths[key]), 10)\n",
    "        for interval in objects_at_start\n",
    "    ])\n",
    "    for key in bboxes_cydet\n",
    "})\n",
    "\n",
    "visualize_cydet([objects_duplicated])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining New Events through Composition and Manipulation Functions for Cyclist Detection\n",
    "\n",
    "Now that we have that basic understanding of Rekall's data representation, let's look at some more complex manipulation functions to try to make a cyclist detector.\n",
    "\n",
    "First, let's look at the [`join`](https://rekallpy.readthedocs.io/en/latest/index.html#rekall.IntervalSet.join) function. This function computes the cross product of two `IntervalSet`s, filters the resulting pairs by a predicate, and then merges the resulting pairs back into a single `Interval` using a merge operation:\n",
    "\n",
    "![simple_join.png](https://olimar.stanford.edu/hdd/rekall_tutorials/simple_join.png)\n",
    "\n",
    "Here's an example of using a `join` operation to create an `IntervalSetMapping` object containing instances of a `person` bounding box overlapping with a `bicycle` bounding box.\n",
    "```Python\n",
    "person_intersect_bike = person.join(\n",
    "    bikes,\n",
    "    predicate = and_pred(\n",
    "        Bounds3D.T(equal()),\n",
    "        Bounds3D.X(overlaps()),\n",
    "        Bounds3D.Y(overlaps())\n",
    "    ),\n",
    "    merge_op = lambda interval1, interval2: Interval(\n",
    "        interval1['bounds'].span(interval2['bounds'])\n",
    "    ),\n",
    "    window = 0.0,\n",
    "    progress_bar = True\n",
    ")\n",
    "```\n",
    "\n",
    "This function joins `person` and `bikes`. The predicate expects a function of the following format:\n",
    "```Python\n",
    "def predicate(interval1, interval2):\n",
    "    # return True or False\n",
    "```\n",
    "\n",
    "We provide a number of spatial and temporal predicates in Rekall, outlined [here](https://rekallpy.readthedocs.io/en/latest/source/rekall.predicates.html). In this case, we're only keeping pairs of (person detection, bike detection) if they have the same time bounds (`Bounds3D.T(equal())`), and the `X` and `Y` bounds overlap (`Bounds3D.X(overlaps())`, `Bounds3D.Y(overlaps())`). The `and_pred` wrapper takes in an arbitrary number of predicates and makes sure that all of them pass.\n",
    "\n",
    "The `merge_op` expects a function of this form:\n",
    "```Python\n",
    "def merge_op(interval1, interval2):\n",
    "    # return a new Interval\n",
    "```\n",
    "\n",
    "In this case, we are returning a new Interval whose bounds span both the Intervals in the pair - basically, the minimum bounding box that covers both of them.\n",
    "\n",
    "We pass in a `window` of `0.0` - this is an optimization that limits the pairs in the cross product to only those Intervals whose time bounds are apart from each other by `window` or less time. A `window` value of `0` limits the pairs to only those that overlap. Since we're already filtering by that in the time dimension, we know that this optimization won't change our results.\n",
    "\n",
    "Finally, we pass `progress_bar=True` just to visualize a progress bar while we wait for this computation to complete (there are a lot of detections to process).\n",
    "\n",
    "Let's run this function and visualize the results below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:11<00:00,  5.67s/it]\n"
     ]
    }
   ],
   "source": [
    "# Use the join above to construct bounding boxes where a person and bike overlap!\n",
    "import time\n",
    "t = time.time()\n",
    "person_intersect_bike = person.join(\n",
    "    bikes,\n",
    "    predicate = and_pred(\n",
    "        Bounds3D.T(equal()),\n",
    "        Bounds3D.X(overlaps()),\n",
    "        Bounds3D.Y(overlaps())\n",
    "    ),\n",
    "    merge_op = lambda interval1, interval2: Interval(\n",
    "        interval1['bounds'].span(interval2['bounds'])\n",
    "    ),\n",
    "    window = 0.0,\n",
    "    progress_bar = True\n",
    ")\n",
    "t = time.time() - t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost:  11.363000631332397\n"
     ]
    }
   ],
   "source": [
    "print(\"Time cost: \", t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c36b45ba67124c919c51fbe6be3bcf62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VGridWidget(vgrid_spec={'compressed': True, 'data': b'x\\x9c\\xd4\\x9d\\xcb\\xae\\xa4\\xc9u\\x9d_\\xc5\\xe0\\xd8 \\xe2~\\xf…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_helper([person_intersect_bike, bikes, person])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4b0f97e046947c68e6f25712999d882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VGridWidget(vgrid_spec={'compressed': True, 'data': b'x\\x9c\\xd4\\x9d\\xcb\\xae\\xa4\\xc9u\\x9d_\\xc5\\xe0\\xd8 \\xe2~\\xf…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_helper([person_intersect_bike])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "You've now used a simple Rekall query to detect bicyclists by composing person detections with bicycle detections.\n",
    "\n",
    "Next, check out the parking space detection tutorial to take a deeper dive into some of Rekall's functions and detect empty parking spaces using nothing more than the outputs of an off-the-shelf object detector!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
